{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e57fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3055f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import camel_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daa029e1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package camel_tools:\n",
      "\n",
      "NAME\n",
      "    camel_tools\n",
      "\n",
      "DESCRIPTION\n",
      "    A suite of Arabic natural language processing tools developed by the CAMeL Lab\n",
      "    at New York University Abu Dhabi.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    cli (package)\n",
      "    data (package)\n",
      "    dialectid (package)\n",
      "    disambig (package)\n",
      "    morphology (package)\n",
      "    ner (package)\n",
      "    sentiment (package)\n",
      "    tagger (package)\n",
      "    tokenizers (package)\n",
      "    utils (package)\n",
      "\n",
      "DATA\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "    version_file = r'C:\\Users\\User\\anaconda3\\lib\\site-packages\\camel_tools...\n",
      "    version_fp = <_io.TextIOWrapper name='C:\\\\Users\\\\User\\\\anacon...\\camel...\n",
      "\n",
      "VERSION\n",
      "    1.2.0\n",
      "\n",
      "FILE\n",
      "    c:\\users\\user\\anaconda3\\lib\\site-packages\\camel_tools\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(camel_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b42b93",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1b5fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers_punctuations (text):\n",
    "    clean_text = re.sub('\\w*\\d\\w*', ' ', str(text))\n",
    "    clean_text = re.sub('[%s]' % re.escape(string.punctuation), ' ', clean_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f63d6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar_text_correction (text):\n",
    "    correct_text = re.sub(r'،|؛', ' ', str(text))\n",
    "    correct_text = re.sub(r'\\s[A-Z]{1}\\s|\\s[a-z]{1}\\s', ' ', str(correct_text))\n",
    "    correct_text = re.sub(r'\\s[ا-ي]\\s', ' ', str(correct_text))\n",
    "    correct_text = re.sub(r'(et)\\s|(al)', ' ', str(correct_text))\n",
    "    correct_text = re.sub(r'لإل','الإ', str(correct_text))\n",
    "    correct_text = re.sub(r'لأل','الأ', str(correct_text))\n",
    "    correct_text = re.sub(r'لال','الا', str(correct_text))\n",
    "    correct_text = re.sub(r'األ','الأ', str(correct_text))\n",
    "    correct_text = re.sub(r'اإل','الإ', str(correct_text))\n",
    "    correct_text = re.sub(r'اال','الا', str(correct_text))\n",
    "    correct_text = re.sub(r'الل','لال', str(correct_text))\n",
    "    correct_text = re.sub(r'الاا','لالا', str(correct_text))\n",
    "    return correct_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d983a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_ar_text(text):\n",
    "    ar_text = re.sub(r\"[A-Z]['\\w]*|[a-z]['\\w]*\", ' ', str(text))\n",
    "    return ar_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a415c193",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a008524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = simple_word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485e99c",
   "metadata": {},
   "source": [
    "##  Removing stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26cfb220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(tokens):\n",
    "    filtered_text = [t for t in tokens if not t in stopwords.words(\"arabic\")]\n",
    "    filtered_text = [t for t in filtered_text if not t in stopwords.words(\"english\")]\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0797f94",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2feebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(filtered_text):\n",
    "    cv = CountVectorizer()\n",
    "    transformed_text = cv.fit_transform(filtered_text)\n",
    "    vector_table = pd.DataFrame(transformed_text.toarray(), columns=cv.get_feature_names())\n",
    "    return vector_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913bad11",
   "metadata": {},
   "source": [
    "## word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b28eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(word_list):\n",
    "    counts = Counter(word_list)\n",
    "    # Reverse the key/values in the dictionary for sorting\n",
    "    word_counts = list(zip(counts.values(), counts.keys()))\n",
    "\n",
    "    # Sort the list by count\n",
    "    word_counts = sorted(word_counts, reverse=True)\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a73e5e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_counts(counts):\n",
    "    word_lengths = pd.Series([len(x) for x in counts])\n",
    "\n",
    "    ax = word_lengths.hist(bins=15)\n",
    "    ax.set(xlabel='Word Lengths', ylabel='Frequency', title='Distribution of Word Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e646c41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57f71347",
   "metadata": {},
   "source": [
    "## Document Similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f678aea2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open (r'C:\\Users\\User\\Dropbox\\PC\\Documents\\python\\articles\\artic14.txt', 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26fe56ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (r'C:\\Users\\User\\Dropbox\\PC\\Documents\\python\\articles\\artic15.txt', 'r', encoding='utf-8') as file:\n",
    "    content2 = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ff81295",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (r'C:\\Users\\User\\Dropbox\\PC\\Documents\\python\\articles\\artic16.txt', 'r', encoding='utf-8') as file:\n",
    "    content3 = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4f815d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = remove_numbers_punctuations(content)\n",
    "content = ar_text_correction(content)\n",
    "content = only_ar_text(content)\n",
    "content = tokenize(content)\n",
    "content = remove_stop_words(content)\n",
    "# content = vectorizer(content)\n",
    "content_counter = word_counter(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a03f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_content = \" \".join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c23dc5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "42e00d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "content2 = remove_numbers_punctuations(content2)\n",
    "content2 = ar_text_correction(content2)\n",
    "content2 = only_ar_text(content2)\n",
    "content2 = tokenize(content2)\n",
    "content2 = remove_stop_words(content2)\n",
    "# content2 = vectorizer(content2)\n",
    "content2_counter = word_counter(content2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08da0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_content2 = \" \".join(content2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "07591393",
   "metadata": {},
   "outputs": [],
   "source": [
    "content3 = remove_numbers_punctuations(content3)\n",
    "content3 = ar_text_correction(content3)\n",
    "content3 = only_ar_text(content3)\n",
    "content3 = tokenize(content3)\n",
    "content3 = remove_stop_words(content3)\n",
    "# content3 = vectorizer(content3)\n",
    "content3_counter = word_counter(content3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6fa8e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_content3 = \" \".join(content3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e8629",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [clean_content, clean_content2, clean_content3]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2fcdd",
   "metadata": {},
   "source": [
    "## Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc0318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33705ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b34a6d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.21648862]]), array([[0.13334312]]), array([[0.11125456]])]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all of the combinations of 5 take 2 as well as the pairs of phrases\n",
    "pairs = list(combinations(range(len(corpus)),2))\n",
    "combos = [(corpus[a_index], corpus[b_index]) for (a_index, b_index) in pairs]\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "# calculate the cosine similarity for all pairs of phrases and sort by most similar\n",
    "results = [cosine_similarity([X[a_index]], [X[b_index]]) for (a_index, b_index) in\n",
    "pairs]\n",
    "sorted(zip(results, combos), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4489e92c",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ea83f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5717a6e3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_tfidf = TfidfVectorizer()\n",
    "X_tfidf = cv_tfidf.fit_transform(corpus).toarray()\n",
    "pd.DataFrame(X_tfidf, columns=cv_tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48207e31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_tfidf = [cosine_similarity([X_tfidf[a_index]], [X_tfidf[b_index]]) for (a_index, b_index) in pairs]\n",
    "sorted(zip(results_tfidf, combos), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84916459",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_counter = word_counter(vector)\n",
    "#clean_content = \" \".join(content6)\n",
    "content_counter[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b36455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
